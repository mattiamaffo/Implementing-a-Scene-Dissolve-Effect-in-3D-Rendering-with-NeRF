# Implementing-a-Scene-Dissolve-Effect-in-3D-Rendering-with-NeRF


[NeRF](http://www.matthewtancik.com/nerf) (Neural Radiance Fields) is a method that achieves state-of-the-art results for synthesizing novel views of complex scenes. Here are some videos generated by this repository (you can find it in the results or assets folder):

![](nerf-pytorch/assets/radial_dissolve.gif)
![](nerf-pytorch/assets/thanos_dissolve.gif)

The code for the NeRF model is based on authors' Tensorflow implementation [here](https://github.com/bmild/nerf), and this project explores and implements a scene dissolve effect using this model, allowing for smooth and controlled transitions between different 3D views, plus an additional post-processing part.

## Installation

```
git clone https://github.com/mattiamaffo/Implementing-a-Scene-Dissolve-Effect-in-3D-Rendering-with-NeRF.git
cd nerf-pytorch
pip install -r requirements.txt
```

<details>
  <summary> Dependencies (click to expand) </summary>
  
  ## Dependencies
  - PyTorch 1.4
  - matplotlib
  - numpy
  - imageio
  - imageio-ffmpeg
  - configargparse
  
</details>

## How To Run?

### Quick Start

Download data for two example datasets: `lego` and `fern`
```
bash download_example_data.sh
```

To train a low-res `lego` NeRF:
```
python run_nerf.py --config configs/lego.txt
```
After training for 100k iterations, you can find the following video:

![](https://user-images.githubusercontent.com/7057863/78473103-9353b300-7770-11ea-98ed-6ba2d877b62c.gif)

---

To train a low-res `fern` NeRF:
```
python run_nerf.py --config configs/fern.txt
```
After training for 200k iterations, you can find the following video:

![](https://user-images.githubusercontent.com/7057863/78473081-58ea1600-7770-11ea-92ce-2bbf6a3f9add.gif)

---

### More Datasets
To play with other scenes presented in the paper, download the data [here](https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1). Place the downloaded dataset according to the following directory structure:
```
├── configs                                                                                                       
│   ├── ...                                                                                     
│                                                                                               
├── data                                                                                                                                                                                                       
│   ├── nerf_llff_data                                                                                                  
│   │   └── fern                                                                                                                             
│   │   └── flower  # downloaded llff dataset                                                                                  
│   │   └── horns   # downloaded llff dataset
|   |   └── ...
|   ├── nerf_synthetic
|   |   └── lego
|   |   └── ship    # downloaded synthetic dataset
|   |   └── ...
```

---

To train NeRF on different datasets: 

```
python run_nerf.py --config configs/{DATASET}.txt
```

replace `{DATASET}` with `trex` | `horns` | `flower` | `fortress` | `lego` | etc.

---

To test NeRF trained on different datasets: 

```
python run_nerf.py --config configs/{DATASET}.txt --render_only
```

replace `{DATASET}` with `trex` | `horns` | `flower` | `fortress` | `lego` | etc.


### Pre-trained Models

You can download the pre-trained models [here](https://drive.google.com/drive/folders/1jIr8dkvefrQmv737fFm2isiT6tqpbTbv). Place the downloaded directory in `./logs` in order to test it later. See the following directory structure for an example:

```
├── logs 
│   ├── fern_test
│   ├── flower_test  # downloaded logs
│   ├── trex_test    # downloaded logs
```

## Method
The dissolve effect in this project is achieved by modulating the density and opacity of the scene during rendering. This process allows objects or entire scenes to gradually appear or disappear, creating smooth transitions between different views.
The implementation in nerf_dissolve.py introduces multiple techniques for achieving progressive scene fading.

To run the rendering phase, with a pre-trained model:
```
python run_nerf.py --config configs/lego.txt --ft_path logs/blender_lego/200000.tar --render_only

```

IMPORTANT: In order to try different dissolution effects, you need to change this row in the run_nerf.py (raw2outputs function) file:

```
sigma, dissolve_mask = galaxy_swirl_dissolve(raw, pts, frame_idx, total_frames)
```
This is important because in the raw2outputs function, we implement the dissolve part of the project. In fact, after retrieving the parameters from the neural model, in the rendering phase, the parameters are leveraged with a dissolve mask that is useful to decrease the density of each point on the ray.

## Citation
Kudos to the authors for their amazing results:
```
@misc{mildenhall2020nerf,
    title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
    author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
    year={2020},
    eprint={2003.08934},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

However, if you find this implementation or pre-trained models helpful, please consider to cite:
```
@misc{lin2020nerfpytorch,
  title={NeRF-pytorch},
  author={Yen-Chen, Lin},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished={\url{https://github.com/yenchenlin/nerf-pytorch/}},
  year={2020}
}
```
